{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256d5511",
   "metadata": {},
   "source": [
    "# `DP-900`: _Microsoft Azure Data Fundamentals_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe05fc6",
   "metadata": {},
   "source": [
    "## `1.` Data Workloads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0398255e",
   "metadata": {},
   "source": [
    "### Database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb5ec0",
   "metadata": {},
   "source": [
    "- A `database` is designed for Online Transaction Processing (`OLTP`), which handles day-to-day operations and transactions\n",
    "- A `database` is optimized for quick, real-time operations like creating, reading, updating, and deleting data. It's the engine behind most applications, from e-commerce websites to banking systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf47deb",
   "metadata": {},
   "source": [
    "#### `Purpose`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2055ca47",
   "metadata": {},
   "source": [
    "To support daily operational tasks and transactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c26b9",
   "metadata": {},
   "source": [
    "#### `Data Type`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1e948f",
   "metadata": {},
   "source": [
    "Typically stores real-time, current data from a single source or application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30118f",
   "metadata": {},
   "source": [
    "#### `Structure`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7dd9c9",
   "metadata": {},
   "source": [
    "Highly normalized to reduce data redundancy, which means data is split into multiple tables with specific relationships. This is efficient for transactional processes but can be complex for large-scale queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779156a8",
   "metadata": {},
   "source": [
    "#### `Queries`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25a09b",
   "metadata": {},
   "source": [
    "Queries are simple, focused on retrieving a small number of records quickly to support a specific function (e.g., \"get the customer's order history\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61013817",
   "metadata": {},
   "source": [
    "#### `Users`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eca1922",
   "metadata": {},
   "source": [
    "Designed to handle a high number of concurrent users, each performing small, fast transactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba0559c",
   "metadata": {},
   "source": [
    "### Data warehouse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2540bd00",
   "metadata": {},
   "source": [
    "- A `data warehouse` is designed for Online Analytical Processing (`OLAP`), which is used for analysis and reporting to support business intelligence and decision-making\n",
    "- A `data warehouse` is a central repository that consolidates historical data from multiple sources (including various databases). Its primary goal is to provide a unified, long-term view of a business to help analysts identify trends and patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9659e5f0",
   "metadata": {},
   "source": [
    "#### `Purpose`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f650cb0",
   "metadata": {},
   "source": [
    "To support business intelligence, data analysis, and strategic decision-making\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18da68f",
   "metadata": {},
   "source": [
    "#### `Data Type`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ee173",
   "metadata": {},
   "source": [
    "Stores large volumes of historical data, often aggregated and cleaned from various sources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6133d",
   "metadata": {},
   "source": [
    "#### `Structure`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a7ad6",
   "metadata": {},
   "source": [
    "Often denormalized using a `star` or `snowflake` schema to optimize for fast, complex queries and reporting. This structure allows analysts to easily group and summarize data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8c119c",
   "metadata": {},
   "source": [
    "#### `Queries`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1543bcaa",
   "metadata": {},
   "source": [
    "Queries are complex, often involving large datasets and multiple joins to answer broad business questions (e.g., \"what was our total sales revenue by region for the last five years?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8d8316",
   "metadata": {},
   "source": [
    "#### `Users`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf42c6",
   "metadata": {},
   "source": [
    "Typically has a smaller number of users, such as business analysts and data scientists, who run complex, long-running queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c606d68",
   "metadata": {},
   "source": [
    "### Data warehouse workload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df55b18",
   "metadata": {},
   "source": [
    "#### `1.` Process of loading data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9335eacd",
   "metadata": {},
   "source": [
    "This refers to the `ETL` (Extract, Transform, Load) or `ELT` (Extract, Load, Transform) process. It involves getting data from various sources, cleaning and transforming it, and then loading it into the data warehouse for storage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd2b77",
   "metadata": {},
   "source": [
    "#### `2.` Performing analysis and reporting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d34797",
   "metadata": {},
   "source": [
    "This is the primary function of a data warehouse. It involves running complex queries and using business intelligence (BI) tools to analyze the data and generate reports that help with decision-making.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24a320d",
   "metadata": {},
   "source": [
    "#### `3.` Managing the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f4ad30",
   "metadata": {},
   "source": [
    "This includes tasks like data governance, ensuring data quality, and performing administrative tasks such as backups and security management to maintain the integrity and reliability of the data warehouse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31aa641",
   "metadata": {},
   "source": [
    "#### `4.` Exporting the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1ab617",
   "metadata": {},
   "source": [
    "This involves moving data out of the warehouse to other repositories or applications, often for further processing, use in machine learning models, or to be shared with other systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04330dc2",
   "metadata": {},
   "source": [
    "### Data Warehouse and Data Lake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c5956",
   "metadata": {},
   "source": [
    "#### `Data Warehouse`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e668b9d2",
   "metadata": {},
   "source": [
    "- A `data warehouse` is a centralized repository of `structured`, `processed data`\n",
    "- It's designed for Online Analytical Processing (OLAP), which means it's optimized for business intelligence (BI), reporting, and analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09ca18",
   "metadata": {},
   "source": [
    "#### `Data Lake`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfd7ce8",
   "metadata": {},
   "source": [
    "- A `data lake` is a vast pool of `raw`, `unprocessed data`\n",
    "- It's designed to store all types of `dataâ€”structured`, `semi-structured`, and `unstructured` at a massive scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c1815",
   "metadata": {},
   "source": [
    "### Structured, Semi-structured, and Unstructured Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be571b3",
   "metadata": {},
   "source": [
    "#### `Structured` Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce314253",
   "metadata": {},
   "source": [
    "`Structured` data is the most traditional type of data. It resides in a fixed field within a record or file and is easily searchable because its format is well-defined\n",
    "\n",
    "`Examples`: Relational databases, CSV files, and spreadsheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0fe473",
   "metadata": {},
   "source": [
    "#### `Semi-structured` Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18508a0a",
   "metadata": {},
   "source": [
    "`Semi-structured` data doesn't fit into the rigid rows and columns of structured data, but it does contain tags or other markers to enforce a hierarchy and organize the data\n",
    "\n",
    "`Examples`: JSON files, XML files, and emails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4bc749",
   "metadata": {},
   "source": [
    "#### `SUnstructured` Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc988e",
   "metadata": {},
   "source": [
    "`Unstructured` data is the opposite of structured data. It has no predefined format, making it difficult to search and analyze with traditional methods. It makes up the vast majority of data in the world today\n",
    "\n",
    "`Examples`: Text documents, social media posts, images, audio files, and videos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f6157",
   "metadata": {},
   "source": [
    "### Azure Batch Process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443587e",
   "metadata": {},
   "source": [
    "#### `1.` Prepare your data and applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b15c69",
   "metadata": {},
   "source": [
    "You start by uploading the input data and the application files (e.g., executables, scripts) that will process this data to an Azure Storage account, typically Azure Blob Storage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4ab232",
   "metadata": {},
   "source": [
    "#### `2.` Create a Batch pool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63096ef",
   "metadata": {},
   "source": [
    "A pool is a collection of compute nodes (VMs) that will execute your tasks. When you create a pool, you specify the number of nodes, their size (which determines CPU and memory), the operating system (Windows or Linux), and how applications should be installed on them. You can also configure auto-scaling to automatically adjust the number of nodes based on the workload, which helps optimize costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6848f1e",
   "metadata": {},
   "source": [
    "#### `3.` Create a job and tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c44be0",
   "metadata": {},
   "source": [
    "A job is a logical container for a collection of tasks. A task is a single unit of work that will run on a compute node. You define the tasks within a job, and each task specifies the command line to be executed and any input files it needs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25839a7",
   "metadata": {},
   "source": [
    "#### `4.` Execute the tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ec1f4",
   "metadata": {},
   "source": [
    "The Batch service automatically schedules the tasks to run on the available compute nodes in the pool. It manages the queueing, execution, and retries of tasks. Before a task runs, it can download the necessary input files and applications from Azure Storage to the assigned node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcc7d47",
   "metadata": {},
   "source": [
    "#### `5.` Monitor and retrieve output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e7fcc1",
   "metadata": {},
   "source": [
    "While the tasks are running, you can monitor their progress. Once tasks are complete, they can upload their output data back to Azure Storage. You can then download and process the final results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac02e887",
   "metadata": {},
   "source": [
    "### Azure Real-time Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96dea95",
   "metadata": {},
   "source": [
    "#### `1.` Data Ingestion Services\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32901187",
   "metadata": {},
   "source": [
    "These services are designed to handle high-throughput data streams from various sources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c0abd4",
   "metadata": {},
   "source": [
    "##### Azure Event Hubs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fdd27c",
   "metadata": {},
   "source": [
    "This is a fully managed, cloud-native service from Microsoft. It's designed to ingest massive volumes of data from a wide range of sources, like applications, websites, and IoT devices. A key benefit is that it's a platform-as-a-service (PaaS), so you don't have to worry about managing the underlying infrastructure, which makes it easy to set up and scale. Event Hubs also has a native Kafka protocol endpoint, allowing existing Kafka applications to connect without code changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e22e094",
   "metadata": {},
   "source": [
    "##### Azure IoT Hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739bdd8",
   "metadata": {},
   "source": [
    "This service is specifically for Internet of Things (IoT) scenarios. While it also ingests high-volume data streams, its core purpose is to provide a secure and bidirectional communication channel between IoT devices and the cloud. It offers rich features for device management, security, and two-way messaging, allowing you to send commands back to devices. This is what distinguishes it from Event Hubs, which is primarily a one-way data ingestion service\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e43366e",
   "metadata": {},
   "source": [
    "##### Apache Kafka\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f573ff7",
   "metadata": {},
   "source": [
    "This is a powerful, open-source, distributed event-streaming platform. It's known for its high throughput and fault tolerance. Unlike Event Hubs and IoT Hub, Kafka is not a managed service by default; you have to set it up and manage it yourself. This gives you a high degree of control and flexibility, but it comes with a significant operational overhead. Many organizations choose to run Kafka on-premises or use a managed Kafka service from a cloud provider (like Azure HDInsight or Confluent Cloud) to reduce the management burden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bfeda1",
   "metadata": {},
   "source": [
    "#### `2.` Processing/Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e44f0d",
   "metadata": {},
   "source": [
    "These services are the heart of the real-time pipeline, where the actual data transformation and analysis take place\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda6ee4",
   "metadata": {},
   "source": [
    "##### Azure Stream Analytics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925eb3ae",
   "metadata": {},
   "source": [
    "A fully managed, serverless stream processing engine that enables you to run complex, real-time analytics on streaming data. It uses a simple, SQL-like query language, which makes it easy to filter, aggregate, and join data from multiple sources. It's ideal for scenarios like real-time dashboards, alerting, and anomaly detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff88011f",
   "metadata": {},
   "source": [
    "##### Azure Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dd187c",
   "metadata": {},
   "source": [
    "An event-driven, serverless compute platform. You can use it to process data streams in real-time by triggering functions based on new data arriving in Event Hubs or IoT Hub. Functions are a great choice for implementing custom, lightweight processing logic that doesn't fit a standard SQL-based query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56307c51",
   "metadata": {},
   "source": [
    "##### Azure Databricks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d62c94d",
   "metadata": {},
   "source": [
    "A fast, powerful, Apache Spark-based analytics platform. While it can be used for batch processing, its Structured Streaming capabilities are excellent for real-time processing of large-scale streaming data. It's a more powerful and flexible option than Stream Analytics for complex machine learning tasks or when you need to write custom logic in Python, Scala, or R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcfa724",
   "metadata": {},
   "source": [
    "#### `3.` Data Storage Services\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee9c9d",
   "metadata": {},
   "source": [
    "After processing, the data needs to be stored for various purposes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef039d",
   "metadata": {},
   "source": [
    "##### Azure Cosmos DB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62141c18",
   "metadata": {},
   "source": [
    "A globally distributed, multi-model database service that's ideal for storing the results of your real-time processing. Its low-latency read and write capabilities make it perfect for powering real-time dashboards and applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9379795",
   "metadata": {},
   "source": [
    "##### Azure Data Lake Storage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fcbd0d",
   "metadata": {},
   "source": [
    "A massively scalable and secure data lake service. It's often used as a long-term storage solution for raw or processed streaming data, which can later be used for historical analysis or machine learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38620b",
   "metadata": {},
   "source": [
    "#### `4.` Visualization and Action Services\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aad277",
   "metadata": {},
   "source": [
    "These services allow you to act on the insights derived from your real-time data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240a2989",
   "metadata": {},
   "source": [
    "##### Power BI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8511d5",
   "metadata": {},
   "source": [
    "A business analytics service that can be used to create real-time dashboards and reports from the output of Stream Analytics or other storage services\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8523e01a",
   "metadata": {},
   "source": [
    "##### Azure Functions/Logic Apps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f92435",
   "metadata": {},
   "source": [
    "You can use these services to trigger actions based on the processed data. For example, a function could send an email or an SMS alert if an anomaly is detected, or a Logic App could initiate a workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6322d708",
   "metadata": {},
   "source": [
    "These services allow you to act on the insights derived from your real-time data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0667c237",
   "metadata": {},
   "source": [
    "#### `Example` Real-Time Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a06c9e8",
   "metadata": {},
   "source": [
    "`Ingestion`: IoT devices send telemetry data to an Azure IoT Hub\n",
    "\n",
    "`Processing`: An Azure Stream Analytics job ingests the data from IoT Hub, uses a SQL query to calculate a rolling average, and checks for anomalies\n",
    "\n",
    "`Storage`: The job outputs the aggregated data to Azure Cosmos DB for a real-time dashboard\n",
    "\n",
    "`Action`: If an anomaly is detected, the Stream Analytics job can also send an alert to an Azure Functions app, which then sends an email to an operations team.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8140987",
   "metadata": {},
   "source": [
    "In Azure, a `resource group` is a fundamental organizational unit that serves as a logical container for your Azure resources. Think of it as a folder for your cloud assets. All resources in a resource group are managed as a single unit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2864bdb",
   "metadata": {},
   "source": [
    "## `2.` Data Analytics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ac3eb0",
   "metadata": {},
   "source": [
    "### Azure data explorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f6e3a",
   "metadata": {},
   "source": [
    "- `Azure Data Explorer` is a fully managed, high-performance, big data analytics platform that makes it easy to analyze high volumes of data in near real time. The Azure Data Explorer toolbox gives you an end-to-end solution for data ingestion, query, visualization, and management\n",
    "- By analyzing structured, semi-structured, and unstructured data across time series, and by using Machine Learning, `Azure Data Explorer` makes it simple to extract key insights, spot patterns and trends, and create forecasting models.\n",
    "- `Azure Data Explorer` uses a traditional relational model, organizing data into tables with strongly typed schemas. Tables are stored within databases, and a cluster can manage multiple databases.\n",
    "- `Azure Data Explorer` is scalable, secure, robust, and enterprise-ready, and is useful for log analytics, time series analytics, IoT, and general-purpose exploratory analytics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c85e2",
   "metadata": {},
   "source": [
    "#### When should you use Azure Data Explorer?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cfb0c3",
   "metadata": {},
   "source": [
    "Use the following questions to help decide if Azure Data Explorer is right for your use case:\n",
    "\n",
    "- `Interactive analytics`: Is interactive analysis part of the solution? For example, aggregation, correlation, or anomaly detection.\n",
    "- `Variety, Velocity, Volume`: Is your schema diverse? Do you need to ingest massive amounts of data in near real-time?\n",
    "- `Data organization`: Do you want to analyze raw data? For example, not fully curated star schema.\n",
    "- `Query concurrency`: Will multiple users or processes use Azure Data Explorer?\n",
    "- `Build vs Buy`: Do you plan on customizing your data platform?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e189e6",
   "metadata": {},
   "source": [
    "#### Azure Data Explorer flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8fba6b",
   "metadata": {},
   "source": [
    "![IMAGE](/home/saadkh/dataops-bc/src/Images/Azure_Data_Explorer_flow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e167d7",
   "metadata": {},
   "source": [
    "### Azure Storage services\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90269819",
   "metadata": {},
   "source": [
    "#### `1-` Azure Blob Storage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93f5a7f",
   "metadata": {},
   "source": [
    "`What it is`: A massively scalable object store for unstructured data\n",
    "\n",
    "`Use it for`: Storing any kind of text or binary data, such as documents, videos, images, and application backups. It's also the foundation for Azure Data Lake Storage Gen2, making it essential for big data analytics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d4745",
   "metadata": {},
   "source": [
    "#### `2-` Azure Files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86478b5e",
   "metadata": {},
   "source": [
    "`What it is`: A fully managed file share in the cloud, accessible via the standard Server Message Block (SMB) protocol.\n",
    "\n",
    "`Use it for`: \"Lifting and shifting\" on-premises applications to the cloud that rely on traditional file shares. It works just like a shared network drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a702a0e",
   "metadata": {},
   "source": [
    "#### `3-` Azure Queue Storage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64928749",
   "metadata": {},
   "source": [
    "`What it is`: A messaging store for building scalable and reliable applications\n",
    "\n",
    "`Use it for`: Decoupling application components. One part of your app can leave a message in the queue (e.g., \"process this image\"), and another part can pick it up when it has the capacity. It creates a reliable buffer between services. ðŸ“¬\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afedb7de",
   "metadata": {},
   "source": [
    "#### `4-` Azure Table Storage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e56969",
   "metadata": {},
   "source": [
    "`What it is`: A NoSQL key-attribute store\n",
    "\n",
    "`Use it for`: Storing large amounts of structured, non-relational data with a flexible schema. It's great for things like user data for web apps, address books, or device information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8356f6cd",
   "metadata": {},
   "source": [
    "#### `5-` Azure Disk Storage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c883f",
   "metadata": {},
   "source": [
    "`What it is`: High-performance, persistent block storage for Azure Virtual Machines (VMs)\n",
    "\n",
    "`Use it for`: Acting as the virtual hard drive (SSD or HDD) for your Azure VMs, where the operating system, applications, and data are stored\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f047b",
   "metadata": {},
   "source": [
    "### Azure Storage services\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b1165b",
   "metadata": {},
   "source": [
    "### Processing ELT data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac9a9e1",
   "metadata": {},
   "source": [
    "### Processing ETL data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d7a466",
   "metadata": {},
   "source": [
    "## `3.` Relational Data Workloads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd66221",
   "metadata": {},
   "source": [
    "## `4.` Relational Data Management\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fafec2",
   "metadata": {},
   "source": [
    "## `5.` Provisioning & Configuring Relational Data Services\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab02da",
   "metadata": {},
   "source": [
    "## `6.` Azure SQL Querying Techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a16ea",
   "metadata": {},
   "source": [
    "## `7.` Non-relational Data Workloads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b0fc30",
   "metadata": {},
   "source": [
    "## `8.` Azure Cosmos DB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08401737",
   "metadata": {},
   "source": [
    "## `9.` Non-relational Data Management\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306652ce",
   "metadata": {},
   "source": [
    "## `10.` Azure Analytics Workloads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ef059",
   "metadata": {},
   "source": [
    "## `11.` Modern Data Warehousing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768a41d7",
   "metadata": {},
   "source": [
    "## `12.` Azure Data Ingestion & Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af347489",
   "metadata": {},
   "source": [
    "## `13.` Azure Data Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272a23b7",
   "metadata": {},
   "source": [
    "# `AZ-900`: _Microsoft Azure Fundamentals_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d34efaa",
   "metadata": {},
   "source": [
    "# `AZ-104`: _Microsoft Azure Administrator_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataops-bc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
