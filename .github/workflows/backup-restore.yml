name: Postgres Backup

on:
  push:
    branches: [ main ]
  workflow_dispatch:
  schedule:
    - cron: '*/2 * * * *'

jobs:
  backup:
    runs-on: ubuntu-latest

    # Use explicit service env values here (don't use ${VAR} interpolation that isn't defined).
    services:
      db:
        image: postgres:17-alpine
        env:
          POSTGRES_USER: bootcamp_admin
          POSTGRES_PASSWORD: secure_password
          POSTGRES_DB: bootcamp_db
        # Avoid mounting runner paths as /var/lib/postgresql/data to prevent permission errors.
        # If you need persistent volumes across runs, consider pushing artifacts or using an external store.
        ports:
          - 5434:5432
        options: >-
          --health-cmd "pg_isready -U bootcamp_admin -d bootcamp_db"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          --health-start-period 60s

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Prepare workspace
        run: |
          set -euo pipefail
          mkdir -p "$GITHUB_WORKSPACE/postgres_backups"

      - name: Run pg_dump inside Postgres service container (no mounts on runner)
        env:
          DB_USER: bootcamp_admin
          DB_PASSWORD: secure_password
          DB_NAME: bootcamp_db
        run: |
          set -euo pipefail

          # Find the Postgres service container created by Actions (match by image)
          CONTAINER_ID=$(docker ps --filter "ancestor=postgres:17-alpine" --format "{{.ID}}" | head -n1)
          if [ -z "$CONTAINER_ID" ]; then
            echo "ERROR: Postgres service container not found. Listing running containers:"
            docker ps --format "table {{.ID}}\t{{.Image}}\t{{.Names}}"
            exit 1
          fi
          echo "Using Postgres container: $CONTAINER_ID"

          # Wait for Postgres to be ready inside the container
          until docker exec "$CONTAINER_ID" pg_isready -U "$DB_USER" > /dev/null 2>&1; do
            echo "Waiting for Postgres inside container..."
            sleep 2
          done

          TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)
          OUTFILE="$GITHUB_WORKSPACE/postgres_backups/${DB_NAME}_${TIMESTAMP}.sql.gz"

          # Run pg_dump inside the service container and write the gzipped output into the runner workspace
          docker exec -e PGPASSWORD="$DB_PASSWORD" "$CONTAINER_ID" pg_dump -U "$DB_USER" "$DB_NAME" | gzip > "$OUTFILE"

          if [ "${PIPESTATUS[0]}" -ne 0 ]; then
            echo "ERROR: pg_dump inside container failed"
            exit 1
          fi

          echo "Backup saved to $OUTFILE"

      - name: "Debug: show backups directory"
        run: |
          echo "Workspace: $GITHUB_WORKSPACE"
          ls -la "$GITHUB_WORKSPACE" || true
          echo "Backups dir contents:"
          ls -la "$GITHUB_WORKSPACE/postgres_backups" || echo "postgres_backups not found"
          echo "Find .gz files:"
          find "$GITHUB_WORKSPACE/postgres_backups" -maxdepth 1 -type f -name '*.gz' -ls || true

      - name: Generate backups CSV
        run: |
          set -euo pipefail
          OUT_DIR="$GITHUB_WORKSPACE/postgres_backups"
          mkdir -p "$OUT_DIR"
          OUT="$OUT_DIR/backups.csv"
          echo "filename,path,timestamp,size_bytes" > "$OUT"
          shopt -s nullglob || true
          for f in "$OUT_DIR"/*.gz; do
            [ -e "$f" ] || continue
            fn=$(basename "$f")
            mtime=$(date -u -d "@$(stat -c %Y "$f")" +"%Y-%m-%dT%H:%M:%SZ")
            size=$(stat -c %s "$f")
            safe_fn="${fn//,/\\,}"
            echo "${safe_fn},postgres_backups,${mtime},${size}" >> "$OUT"
          done
          echo "Generated $OUT"
          ls -la "$OUT_DIR" || true
          sed -n '1,200p' "$OUT" || true

      - name: Upload backup artifact
        uses: actions/upload-artifact@v4
        with:
          name: postgres-backups
          path: ${{ github.workspace }}/postgres_backups/**